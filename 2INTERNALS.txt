ID3



import pandas as pd
df = pd.read_csv('PlayTennis.csv')
print("\n Input Data Set is:\n", df)

t=df.keys()[-1]
print('Target Attribute is: ', t)
attribute_names = list(df.keys())
attribute_names.remove(t) 
print('Predicting Attributes: ', attribute_names)

import math
def entropy(probs):  
    return sum( [-prob*math.log(prob, 2) for prob in probs])

def entropy_of_list(ls,value):  
    from collections import Counter
    cnt = Counter(x for x in ls)
    print('Target attribute class count(Yes/No)=',dict(cnt))
    total_instances = len(ls)  
    print("Total no of instances/records associated with {0} is: {1}".format(value,total_instances ))
    probs = [x / total_instances for x in cnt.values()]  
    print("Probability of Class {0} is: {1:.4f}".format(min(cnt),min(probs)))
    print("Probability of Class {0} is: {1:.4f}".format(max(cnt),max(probs)))
    return entropy(probs) 

def information_gain(df, split_attribute, target_attribute,battr):
    print("\n\n-----Information Gain Calculation of ",split_attribute, " --------") 
    df_split = df.groupby(split_attribute)
    glist=[]
    for gname,group in df_split:
        print('Grouped Attribute Values \n',group)
        glist.append(gname) 
    
    glist.reverse()
    nobs = len(df.index) * 1.0   
    df_agg1=df_split.agg({target_attribute:lambda x:entropy_of_list(x, glist.pop())})
    df_agg2=df_split.agg({target_attribute :lambda x:len(x)/nobs})
    
    df_agg1.columns=['Entropy']
    df_agg2.columns=['Proportion']   

    new_entropy = sum( df_agg1['Entropy'] * df_agg2['Proportion'])
    if battr !='S':
        old_entropy = entropy_of_list(df[target_attribute],'S-'+df.iloc[0][df.columns.get_loc(battr)])
    else:
        old_entropy = entropy_of_list(df[target_attribute],battr)
    return old_entropy - new_entropy



def id3(df,target_attribute,attribute_names,default_class=None,default_attr='S'):
    
    from collections import Counter
    cnt = Counter(x for x in df[target_attribute])
    if len(cnt)==1:
        return next(iter(cnt))
    elif df.empty or (not attribute_names):
        return default_class
    else:
        default_class=max(cnt.keys())
        gainz=[]
        for attr in attribute_names:
            ig=information_gain(df,attr,target_attribute,default_attr)
            gainz.append(ig)
            print('Information gain of',attr,'is:',ig)
            
        index_of_max=gainz.index(max(gainz))
        best_attr=attribute_names[index_of_max]
        print("\nAttribute with the maximum gain is:",best_attr)
            
        tree={best_attr:{}}
        remaining_attribute_names=[i for i in attribute_names if i!=best_attr]
            
        for attr_val,data_subset in df.groupby (best_attr):
            subtree=id3(data_subset,target_attribute,remaining_attribute_names,default_class,best_attr)
            tree[best_attr][attr_val]=subtree
        return tree

from pprint import pprint
tree = id3(df,t,attribute_names)
print("\nthe Resultant Decision Tree is:")
pprint(tree)

def classify(instance,tree,default=None):
    attribute=next(iter(tree))
    if instance[attribute] in tree[attribute].keys():
        result = tree[attribute][instance[attribute]]
        if isinstance (result,dict):
            return classify(instance,result)
        else:
            return result
    else:
        return default

df_new = pd.read_csv('PlayTennisTest.csv')
df_new['predicted'] = df_new.apply(classify,axis=1,args=(tree,'?'))
print(df_new)


NAVYE BASE



import numpy as np
import math
import csv

def read_data(filename):
    with open(filename, 'r') as csvfile:
        datareader = csv.reader(csvfile)
        metadata = next(datareader)
        traindata=[]
        for row in datareader:
            traindata.append(row)
    return (metadata, traindata)


def splitDataset(dataset, splitRatio): 
    trainSize = int(len(dataset) * splitRatio)
    trainSet = []
    testset = list(dataset)
    i=0
    while len(trainSet) < trainSize:
        trainSet.append(testset.pop(i))
    return [trainSet, testset]

def classify(data,test):
    total_size = data.shape[0]
    print("training data size=",total_size)
    print("test data size=",test.shape[0])
    target=np.unique(data[:,-1])
    count = np.zeros((target.shape[0]), dtype=np.int32)
    prob = np.zeros((target.shape[0]), dtype=np.float32)
    
    print("target count probability")
    
    for y in range(target.shape[0]):
        for x in range(data.shape[0]):
            if data[x,data.shape[1]-1] == target[y]:
                count[y] += 1
        prob[y]=count[y]/total_size # comptes the probability of target
        print(target[y],"\t",count[y],"\t",prob[y])
        
    prob0 = np.zeros((test.shape[1]-1), dtype=np.float32)
    prob1 = np.zeros((test.shape[1]-1), dtype=np.float32)
    accuracy=0
    print("Instance prediction target")
    for t in range(test.shape[0]):
        for k in range(test.shape[1]-1): 
            count1=count0=0
            for j in range(data.shape[0]):
                if test[t,k]== data[j,k] and data[j,data.shape[1]-1]== target[0]:
                    count0+=1
                elif test[t,k]== data[j,k] and data[j,data.shape[1]-1]== target[1]:
                    count1+=1
            prob0[k]= count0/count[0] 
            prob1[k]= count1/count[1]
    
        probno=prob[0]
        probyes=prob[1]
        for i in range(test.shape[1]-1):
            probno=probno*prob0[i]
            probyes=probyes*prob1[i]
    
        if probno>probyes: 
            predict='no'
        else:
            predict='yes'
        print(t+1,"\t",predict,"\t ",test[t,test.shape[1]-1])
    
        if predict== test[t,test.shape[1]-1]:
            accuracy+=1
        final_accuracy=(accuracy/test.shape[0])*100
        print("accuracy",final_accuracy,"%")
    return

metadata, traindata = read_data("PlayTennis.csv")
splitRatio = 0.6
trainingset, testset = splitDataset(traindata, splitRatio)
training=np.array(trainingset)
testing=np.array(testset)
print("------------------Training Data ------------------ ")
print(trainingset)
print("-------------------Test Data ------------------ ")
print(testset)

classify(training,testing)



ANN



import numpy as np
X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)
y = np.array(([92], [86], [89]), dtype=float)
X = X/np.amax(X,axis=0)
y = y/100


def sigmoid (x):
    return 1/(1 + np.exp(-x))

def derivatives_sigmoid(x):
    return x * (1 - x)


epoch=7000 
learning_rate=0.1 
inputlayer_neurons = 2 
hiddenlayer_neurons = 3 
output_neurons = 1 

wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons)) 
bh=np.random.uniform(size=(1,hiddenlayer_neurons))
wo=np.random.uniform(size=(hiddenlayer_neurons,output_neurons)) 
bo=np.random.uniform(size=(1,output_neurons))

for i in range(epoch):

    net_h=np.dot(X,wh) + bh 
    sigma_h= sigmoid(net_h) 
    net_o= np.dot(sigma_h,wo)+ bo 
    output = sigmoid(net_o)
    
    deltaK = (y-output)* derivatives_sigmoid(output) 
    deltaH =  deltaK.dot(wo.T) * derivatives_sigmoid(sigma_h) 
    wo = wo + sigma_h.T.dot(deltaK) *learning_rate 
    wh = wh + X.T.dot(deltaH) *learning_rate 

print("Input: \n" + str(X))
print("Actual Output: \n" + str(y))
print("Predicted Output: \n" ,output)





AOSTAR
class Graph:
    def _init_(self, graph, heuristicNodeList, startNode):  #instantiate graph object with graph topology, heuristic values, start node
        
        self.graph = graph
        self.H=heuristicNodeList
        self.start=startNode
        self.parent={}
        self.status={}
        self.solutionGraph={}
     
    def applyAOStar(self):         
        self.aoStar(self.start, False)

    def getNeighbors(self, v):    
        return self.graph.get(v,'')
    
    def getStatus(self,v):        
        return self.status.get(v,0)
    
    def setStatus(self,v, val):   
        self.status[v]=val
    
    def getHeuristicNodeValue(self, n):
        return self.H.get(n,0)    
 
    def setHeuristicNodeValue(self, n, value):
        self.H[n]=value            
        
    
    def printSolution(self):
        print("FOR GRAPH SOLUTION, TRAVERSE THE GRAPH FROM THE START NODE:",self.start)
        print("------------------------------------------------------------")
        print(self.solutionGraph)
        print("------------------------------------------------------------")
        
    def computeMinimumCostChildNodes(self, v):       
        minimumCost=0
        costToChildNodeListDict={}
        costToChildNodeListDict[minimumCost]=[]
        flag=True
        for nodeInfoTupleList in self.getNeighbors(v): 
            cost=0
            nodeList=[]
            for c, weight in nodeInfoTupleList:
                cost=cost+self.getHeuristicNodeValue(c)+weight
                nodeList.append(c)
            
            if flag==True:                    
                costToChildNodeListDict[minimumCost]=nodeList     
                flag=False
            else:                                 
                if minimumCost>cost:
                    minimumCost=cost
                    costToChildNodeListDict[minimumCost]=nodeList 
                
              
        return minimumCost, costToChildNodeListDict[minimumCost]   
                     
    
    def aoStar(self, v, backTracking):    
        
        print("HEURISTIC VALUES  :", self.H)
        print("SOLUTION GRAPH    :", self.solutionGraph)
        print("PROCESSING NODE   :", v)
        print("-----------------------------------------------------------------------------------------")
        
        if self.getStatus(v) >= 0:        
            minimumCost, childNodeList = self.computeMinimumCostChildNodes(v)
            self.setHeuristicNodeValue(v, minimumCost)
            self.setStatus(v,len(childNodeList))
            
            solved=True                    
            for childNode in childNodeList:
                self.parent[childNode]=v
                if self.getStatus(childNode)!=-1:
                    solved=solved & False
            
            if solved==True:             
                self.setStatus(v,-1)    
                self.solutionGraph[v]=childNodeList 
            
            
            if v!=self.start:              
                self.aoStar(self.parent[v], True)   
                
            if backTracking==False:     
                for childNode in childNodeList:  
                    self.setStatus(childNode,0)  
                    self.aoStar(childNode, False) 
                 
        
                                       
h1 = {'A': 1, 'B': 6, 'C': 2, 'D': 12, 'E': 2, 'F': 1, 'G': 5, 'H': 7, 'I': 7, 'J': 1, 'T': 3}
graph1 = {
    'A': [[('B', 1), ('C', 1)], [('D', 1)]],
    'B': [[('G', 1)], [('H', 1)]],
    'C': [[('J', 1)]],
    'D': [[('E', 1), ('F', 1)]],
    'G': [[('I', 1)]]   
}
G1= Graph(graph1, h1, 'A')
G1.applyAOStar() 
G1.printSolution()

h2 = {'A': 1, 'B': 6, 'C': 12, 'D': 10, 'E': 4, 'F': 4, 'G': 5, 'H': 7}   
graph2 = {                                        
    'A': [[('B', 1), ('C', 1)], [('D', 1)]],      
    'B': [[('G', 1)], [('H', 1)]],               
    'D': [[('E', 1), ('F', 1)]]                   
}

G2 = Graph(graph2, h2, 'A')                       
G2.applyAOStar()                                  
G2.printSolution()




ASTAR
import os
clear=lambda : os.system('cls')
clear()



def aStarAlgo(start_node, stop_node):
         
        open_set = set(start_node) 
        closed_set = set()
        g = {} 
        parents = {}
 
        
        g[start_node] = 0
        
        parents[start_node] = start_node
         
         
        while len(open_set) > 0:
            n = None
 
           
            for v in open_set:
                if n == None or g[v] + heuristic(v) < g[n] + heuristic(n):
                    n = v
             
                     
            if n == stop_node or Graph_nodes[n] == None:
                pass
            else:
                for (m, weight) in get_neighbors(n):
                   
                    if m not in open_set and m not in closed_set:
                        open_set.add(m)
                        parents[m] = n
                        g[m] = g[n] + weight
                        
                    else:
                        if g[m] > g[n] + weight:
                           
                            g[m] = g[n] + weight
                           
                            parents[m] = n
                             
                            
                            if m in closed_set:
                                closed_set.remove(m)
                                open_set.add(m)
 
            if n == None:
                print('Path does not exist!')
                return None
 
           
            if n == stop_node:
                path = []
 
                while parents[n] != n:
                    path.append(n)
                    n = parents[n]
 
                path.append(start_node)
 
                path.reverse()
 
                print('Path found: {}'.format(path))
                return path
 
 
    
            open_set.remove(n)
            closed_set.add(n)
 
        print('Path does not exist!')
        return None



def get_neighbors(v):
    if v in Graph_nodes:
        return Graph_nodes[v]
    else:
        return None

def heuristic(n):
        H_dist = {
            'A': 11,
            'B': 6,
            'C': 99,
            'D': 1,
            'E': 7,
            'G': 0             
        }
 
        return H_dist[n]
 

Graph_nodes = {
    
    'A': [('E', 3), ('B',2)],
    'B': [('C', 1),('G',9)] ,
    'E': [('D', 6)],
    'D': [('G', 1)],
     
}
aStarAlgo('A', 'G')



CEA

import csv

with open("CandidateElimination.csv") as f:
    csv_file = csv.reader(f)
    data = list(csv_file)

    s = data[1][:-1]
    g = [['?' for i in range(len(s))] for j in range(len(s))]

    for i in data:
        if i[-1] == "Yes":
            for j in range(len(s)):
                if i[j] != s[j]:
                    s[j] = '?'
                    g[j][j] = '?'

        elif i[-1] == "No":
            for j in range(len(s)):
                if i[j] != s[j]:
                    g[j][j] = s[j]
                else:
                    g[j][j] = "?"
        print("\nSteps of Candidate Elimination Algorithm", data.index(i) + 1)
        print(s)
        print(g)
    gh = []
    for i in g:
        for j in i:
            if j != '?':
                gh.append(i)
                break
    print("\nFinal specific hypothesis:\n", s)

    print("\nFinal general hypothesis:\n", gh)







